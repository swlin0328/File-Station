{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# database\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as XET\n",
    "\n",
    "import sqlalchemy as sqlc\n",
    "from sqlalchemy import exc\n",
    "\n",
    "from sqlalchemy import Table, Column, MetaData, Integer, Computed, String\n",
    "from synology_dsm import SynologyDSM\n",
    "from synology_api import filestation\n",
    "\n",
    "from configparser import ConfigParser, ExtendedInterpolation\n",
    "from time import strftime\n",
    "from tqdm import tqdm\n",
    "\n",
    "config = ConfigParser(interpolation=ExtendedInterpolation())\n",
    "config.read('./config/db_config.ini', encoding='utf-8-sig')\n",
    "\n",
    "db_info = config['database']\n",
    "host_ip = db_info['host_ip']\n",
    "port = db_info['port']\n",
    "user_name = db_info['user_name']\n",
    "password = db_info['password']\n",
    "db_name = db_info['db_name']\n",
    "db_url = db_info['db_url']\n",
    "\n",
    "dataset_path = config['dataset']['dir_path']\n",
    "saved_path = config['dataset']['saved_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQL_Config():\n",
    "    \"\"\"\n",
    "    SQL SERVER 連接設定\n",
    "    \"\"\"\n",
    "    def __init__(self, user=None, password=None, database=None, host_address=None, db_url=None, port=32769):\n",
    "        self.user = user\n",
    "        self.password = password\n",
    "        self.db_name = database\n",
    "        self.host = host_address\n",
    "        self.created_time = strftime('%Y-%m-%d %H:%M:%S')\n",
    "        self.port = port\n",
    "        \n",
    "        if db_url is None:\n",
    "            self.db_url = f\"{user}:{password}@{host_address}:{port}/{database}\"\n",
    "        else:\n",
    "            self.db_url = db_url\n",
    "\n",
    "    def postgreSQL_connect(self):\n",
    "        \"\"\"\n",
    "        進行 SQL SERVER 連接\n",
    "        \"\"\"\n",
    "        print('=====================================================')\n",
    "        print('======== Connect to the remote postgre SQL server ========')\n",
    "        print('=====================================================')\n",
    "        print('Time : {}\\n'.format(strftime('%Y-%m-%d_%H_%M')))\n",
    "        \n",
    "        sql_prefix = \"postgresql+psycopg2://\" + self.db_url\n",
    "            \n",
    "        self.engine = sqlc.create_engine(sql_prefix)\n",
    "        self.db = self.engine.raw_connection()\n",
    "        self.cursor = self.db.cursor()\n",
    "\n",
    "    def commit(self):\n",
    "        \"\"\"\n",
    "        資料庫commit\n",
    "        \"\"\"\n",
    "        try:\n",
    "            trans = self.db\n",
    "            trans.commit()\n",
    "        except:\n",
    "            trans.rollback()\n",
    "\n",
    "    def disconnect(self):\n",
    "        \"\"\"\n",
    "        資料庫離線\n",
    "        \"\"\"\n",
    "        self.db.close()\n",
    "        print('=====================================================')\n",
    "        print('============ Close the remote connection ============')\n",
    "        print('=====================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Table_Creator(SQL_Config):\n",
    "    \"\"\"\n",
    "    Create SQL Table with sqlalchemy\n",
    "    \"\"\"\n",
    "    def __init__(self, user=None, password=None, database=None, host_address=None, db_url=None, port=32769):\n",
    "        super().__init__(user, password, database, host_address, db_url, port)\n",
    "\n",
    "    def create_table4annot(self):\n",
    "        metadata = MetaData()\n",
    "\n",
    "        data = Table(\n",
    "            \"Image_Annot\", metadata,\n",
    "            Column('UUID', Integer, autoincrement=True, primary_key=True),\n",
    "            Column('Name', String),\n",
    "            Column('Pose', String),\n",
    "            Column('Truncated', Integer),\n",
    "            Column('Difficult', Integer),\n",
    "            Column('Xmin', Integer),\n",
    "            Column('Ymin', Integer),\n",
    "            Column('Xmax', Integer),\n",
    "            Column('Ymax', Integer),\n",
    "            Column('File', String),\n",
    "            Column('Dataset', String)\n",
    "            )\n",
    "        metadata.create_all(self.engine)\n",
    "\n",
    "    def create_table4label(self):\n",
    "        metadata = MetaData()\n",
    "\n",
    "        data = Table(\n",
    "            \"Image_Label\", metadata,\n",
    "            Column('Label_ID', Integer),\n",
    "            Column('Name', String, primary_key=True),\n",
    "            Column('Dataset', String, primary_key=True)\n",
    "            )\n",
    "\n",
    "        metadata.create_all(self.engine)\n",
    "        \n",
    "    def create_table4image(self):\n",
    "        metadata = MetaData()\n",
    "\n",
    "        data = Table(\n",
    "            \"Image_Info\", metadata,\n",
    "            Column('File_Name', String, primary_key=True),\n",
    "            Column('Width', Integer),\n",
    "            Column('Height', Integer),\n",
    "            Column('Depth', Integer),\n",
    "            Column('Dataset', String, primary_key=True)\n",
    "            )\n",
    "\n",
    "        metadata.create_all(self.engine)\n",
    "        \n",
    "    def create_table4dataset(self):\n",
    "        metadata = MetaData()\n",
    "\n",
    "        data = Table(\n",
    "            \"Dataset\", metadata,\n",
    "            Column('Name', String),\n",
    "            Column('Prefix_Path', String, primary_key=True),\n",
    "            )\n",
    "\n",
    "        metadata.create_all(self.engine)\n",
    "        \n",
    "    def start(self):\n",
    "        self.postgreSQL_connect()\n",
    "        \n",
    "        self.create_table4annot()\n",
    "        self.create_table4label()\n",
    "        self.create_table4image()\n",
    "        self.create_table4dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "======== Connect to the remote postgre SQL server ========\n",
      "=====================================================\n",
      "Time : 2020-12-23_23_01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Table_Creator(user=user_name, password=password, database=db_name, host_address=host_ip, port=port).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NAS_Config():\n",
    "    \"\"\"\n",
    "    Synology DSM 連接設定\n",
    "    \"\"\"\n",
    "    def __init__(self, user=None, password=None, host_address=None, port=\"5000\"):\n",
    "        self.user = user\n",
    "        self.password = password\n",
    "        self.host = host_address\n",
    "        self.created_time = strftime('%Y-%m-%d %H:%M:%S')\n",
    "        self.port = port\n",
    "        \n",
    "        self.connect()\n",
    "\n",
    "    def connect(self):\n",
    "        \"\"\"\n",
    "        連接 Synology NAS \n",
    "        \"\"\"\n",
    "        print('=====================================================')\n",
    "        print('======== Connect to the remote NAS server ========')\n",
    "        print('=====================================================')\n",
    "        print('Time : {}\\n'.format(strftime('%Y-%m-%d_%H_%M')))\n",
    "            \n",
    "        self.api = SynologyDSM(self.host, self.port, self.user, self.password)\n",
    "\n",
    "    def print_system_info(self):\n",
    "        \"\"\"\n",
    "        顯示系統資訊\n",
    "        \"\"\"\n",
    "        print(\"=== Information ===\")\n",
    "        self.api.information.update()\n",
    "        print(\"Model:           \" + str(self.api.information.model))\n",
    "        print(\"RAM:             \" + str(self.api.information.ram) + \" MB\")\n",
    "        print(\"Temperature:     \" + str(self.api.information.temperature) + \" °C\")\n",
    "        print(\"--\")\n",
    "\n",
    "    def print_utilisation(self):\n",
    "        \"\"\"\n",
    "        顯示資源使用率\n",
    "        \"\"\"\n",
    "        self.api.utilisation.update()\n",
    "        print(\"CPU Load:        \" + str(self.api.utilisation.cpu_total_load) + \" %\")\n",
    "        print(\"Memory Use:      \" + str(self.api.utilisation.memory_real_usage) + \" %\")\n",
    "        print(\"Net Up:          \" + str(self.api.utilisation.network_up()))\n",
    "        print(\"Net Down:        \" + str(self.api.utilisation.network_down()))\n",
    "        print(\"--\")\n",
    "\n",
    "    def print_storage_info(self):  \n",
    "        \"\"\"\n",
    "        顯示儲存裝置資訊\n",
    "        \"\"\"\n",
    "        print(\"=== Storage ===\")\n",
    "        self.api.storage.update()\n",
    "        for volume_id in self.api.storage.volumes_ids:\n",
    "            print(\"ID:          \" + str(volume_id))\n",
    "            print(\"Status:      \" + str(self.api.storage.volume_status(volume_id)))\n",
    "            print(\"% Used:      \" + str(self.api.storage.volume_percentage_used(volume_id)) + \" %\")\n",
    "            print(\"--\")\n",
    "            \n",
    "        for disk_id in self.api.storage.disks_ids:\n",
    "            print(\"ID:          \" + str(disk_id))\n",
    "            print(\"Name:        \" + str(self.api.storage.disk_name(disk_id)))\n",
    "            print(\"Status:      \" + str(self.api.storage.disk_status(disk_id)))\n",
    "            print(\"Temp:        \" + str(self.api.storage.disk_temp(disk_id)))\n",
    "            print(\"--\")\n",
    "            \n",
    "    def print_shared_folder(self):  \n",
    "        \"\"\"\n",
    "        顯示共用空間資訊\n",
    "        \"\"\" \n",
    "        print(\"=== Shared Folders ===\")\n",
    "        self.api.share.update()\n",
    "        for share_uuid in self.api.share.shares_uuids:\n",
    "            print(\"Share name:        \" + str(self.api.share.share_name(share_uuid)))\n",
    "            print(\"Share path:        \" + str(self.api.share.share_path(share_uuid)))\n",
    "            print(\"Space used:        \" + str(self.api.share.share_size(share_uuid, human_readable=True)))\n",
    "            print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Filestation_Config():\n",
    "    \"\"\"\n",
    "    Synology Filestation 連接設定\n",
    "    \"\"\"\n",
    "    def __init__(self, user=None, password=None, host_address=None, port=\"5000\"):\n",
    "        self.user = user\n",
    "        self.password = password\n",
    "        self.host = host_address\n",
    "        self.created_time = strftime('%Y-%m-%d %H:%M:%S')\n",
    "        self.port = port\n",
    "        \n",
    "        self.connect()\n",
    "\n",
    "    def connect(self):\n",
    "        \"\"\"\n",
    "        連接 Synology NAS \n",
    "        \"\"\"\n",
    "        print('=====================================================')\n",
    "        print('======== Connect to the remote filestation ========')\n",
    "        print('=====================================================')\n",
    "        print('Time : {}\\n'.format(strftime('%Y-%m-%d_%H_%M')))\n",
    "            \n",
    "        self.api = filestation.FileStation(self.host, self.port, self.user, self.password)\n",
    "            \n",
    "    def print_shared_folder(self):  \n",
    "        \"\"\"\n",
    "        顯示共用空間資訊\n",
    "        \"\"\" \n",
    "        print(\"=== Shared Folders ===\")\n",
    "        query_info = self.api.get_list_share()\n",
    "        if not query_info['success']:\n",
    "            print('query shared folder failed...')\n",
    "            \n",
    "        for folder_info in query_info['data']['shares']:\n",
    "            if folder_info['isdir']:\n",
    "                print(folder_info['name'])\n",
    "                print(folder_info['path'])\n",
    "                print('---')\n",
    "                \n",
    "    def query_file_list(self, dir_path):  \n",
    "        \"\"\"\n",
    "        顯示資料夾內容\n",
    "        \"\"\" \n",
    "        query_info = self.api.get_file_list(dir_path)\n",
    "        file_df = pd.DataFrame([], columns=[\"Name\", \"Path\"])\n",
    "        if not query_info['success']:\n",
    "            print('query file list failed...')\n",
    "                \n",
    "        for folder_info in query_info['data']['shares']:\n",
    "            print('data list')\n",
    "            if not folder_info['isdir']:\n",
    "                print('name: ', folder_info['name'])\n",
    "                print('path: ', folder_info['path'])\n",
    "                file_df = file_df.append({\"File_Name\": folder_info['name'], \"File_Path\": folder_info['path']}, \n",
    "                                         ignore_index=True)\n",
    "                print('---')\n",
    "                \n",
    "        return file_df\n",
    "    \n",
    "    def query_dir_info(self, dir_path):  \n",
    "        \"\"\"\n",
    "        顯示資料夾內容\n",
    "        \"\"\" \n",
    "        query_info = self.api.get_file_list(dir_path)\n",
    "        dir_dict = {}\n",
    "        if not query_info['success']:\n",
    "            print('query dir list failed...')\n",
    "            \n",
    "        for folder_info in query_info['data']['files']:\n",
    "            print('dir info')\n",
    "            if folder_info['isdir']:\n",
    "                print('name: ', folder_info['name'])\n",
    "                print('path: ', folder_info['path'])\n",
    "                dir_dict[folder_info['name']] = folder_info['path']\n",
    "                print('---')\n",
    "                \n",
    "        return dir_dict\n",
    "    \n",
    "    def download_file(self, path, file_name, dst_path):  \n",
    "        if not os.path.exists(dst_path):\n",
    "            os.makedirs(dst_path)\n",
    "            \n",
    "        file_path = path + '/' + file_name\n",
    "        self.api.get_file(file_path, 'download')\n",
    "        shutil.move(file_name, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "======== Connect to the remote filestation ========\n",
      "=====================================================\n",
      "Time : 2020-12-23_23_01\n",
      "\n",
      "You are now logged in!\n",
      "=== Shared Folders ===\n",
      "ActiveBackupforBusiness\n",
      "/ActiveBackupforBusiness\n",
      "---\n",
      "chat\n",
      "/chat\n",
      "---\n",
      "dataset\n",
      "/dataset\n",
      "---\n",
      "docker\n",
      "/docker\n",
      "---\n",
      "home\n",
      "/home\n",
      "---\n",
      "homes\n",
      "/homes\n",
      "---\n",
      "music\n",
      "/music\n",
      "---\n",
      "nas\n",
      "/nas\n",
      "---\n",
      "photo\n",
      "/photo\n",
      "---\n",
      "video\n",
      "/video\n",
      "---\n",
      "web\n",
      "/web\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "dsm_api = Filestation_Config(user_name, password, host_ip)\n",
    "dsm_api.print_shared_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image_Dataset2DB(SQL_Config):\n",
    "    \"\"\"\n",
    "    Upload the public dataset information to SQL\n",
    "    \"\"\"\n",
    "    def __init__(self, user=None, password=None, database=None, host_address=None, db_url=None, port=32769):\n",
    "        super().__init__(user, password, database, host_address, db_url)\n",
    "        self.connect2NAS()\n",
    "        \n",
    "    def connect2NAS(self):\n",
    "        self.dsm_api = NAS_Config(self.user, self.password, self.host)\n",
    "        self.filestation_api = Filestation_Config(self.user, self.password, self.host)\n",
    "        \n",
    "        print('connct to NAS...')    \n",
    "        self.dsm_api.print_utilisation()\n",
    "        self.dsm_api.print_system_info()\n",
    "\n",
    "    def upload_label(self, label_df):\n",
    "        self.upload_dataset2sql(label_df, \"Image_Label\")    \n",
    "\n",
    "    def upload_BBoxes(self, annot_df):\n",
    "        self.upload_dataset2sql(annot_df, \"Image_Annot\")  \n",
    "        \n",
    "    def upload_imageInfo(self, image_df):  \n",
    "        self.upload_dataset2sql(image_df, \"Image_Info\")\n",
    "        \n",
    "    def upload_datasetInfo(self, dataset_df):\n",
    "        self.upload_dataset2sql(dataset_df, \"Dataset\")      \n",
    "            \n",
    "    def upload_dataset2sql(self, df, table_name, if_exists='append'):\n",
    "        for idx in range(len(df)):\n",
    "            try:\n",
    "                df.iloc[idx:idx+1].to_sql(table_name, self.engine, if_exists=if_exists, index=False)\n",
    "            except exc.IntegrityError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VOC_Dataset(Image_Dataset2DB):\n",
    "    \"\"\"\n",
    "    Extract information of VOC dataset\n",
    "    \"\"\"\n",
    "    def __init__(self, dir_path, dataset_name, \n",
    "                 user=None, password=None, database=None, host_address=None, db_url=None, port=32769):\n",
    "        self.dataset_name = dataset_name\n",
    "        self.dir_path = dir_path\n",
    "        \n",
    "        super().__init__(user, password, database, host_address, db_url)\n",
    "        \n",
    "    def extract_dataset_info(self, nas_path):\n",
    "        dataset_df = pd.DataFrame([], columns=[\"Name\", \"Prefix_Path\"])\n",
    "        dir_dict = self.filestation_api.query_dir_info(nas_path)\n",
    "    \n",
    "        for folder_name in dir_dict.keys():\n",
    "            if self.dataset_name == folder_name:\n",
    "                dataset_df = dataset_df.append({\"Name\": folder_name, \"Prefix_Path\": dir_dict[folder_name]},\n",
    "                                           ignore_index=True)\n",
    "                \n",
    "        self.upload_datasetInfo(dataset_df)\n",
    "    \n",
    "    def extract_label_info(self):\n",
    "        path = self.dir_path + 'Annotations/'\n",
    "        bbox_df = pd.DataFrame([], columns=[\"Name\", \"Pose\", \"Truncated\", \"Difficult\",\n",
    "                                             \"Xmin\", \"Ymin\", \"Xmax\", \"Ymax\",\n",
    "                                             \"File\", \"Dataset\"])\n",
    "        image_df = pd.DataFrame([], columns=[\"File_Name\", \"Width\", \"Height\", \"Depth\", \"Dataset\"])\n",
    "    \n",
    "        file_list = os.listdir(path)\n",
    "    \n",
    "        for file in file_list:\n",
    "            tree = XET.parse(path + file)\n",
    "            root = tree.getroot()\n",
    "            \n",
    "            dataset = root.findall('folder')[0].text\n",
    "            assert(self.dataset_name == dataset)\n",
    "            \n",
    "            file_name = root.findall('filename')[0].text\n",
    "            size = root.findall('size')[0]\n",
    "        \n",
    "            width = int(size[0].text)\n",
    "            height = int(size[1].text)\n",
    "            depth = int(size[2].text)\n",
    "        \n",
    "            image_df = image_df.append({\"File_Name\": file_name,\n",
    "                                        \"Width\": width,\n",
    "                                        \"Height\": height,\n",
    "                                        \"Depth\": depth,\n",
    "                                        \"Dataset\": self.dataset_name},\n",
    "                                       ignore_index=True)\n",
    "            bbox_df = self.extract_BBoxes(root, bbox_df, file_name)    \n",
    "            \n",
    "        self.upload_imageInfo(image_df)\n",
    "        self.upload_BBoxes(bbox_df)\n",
    "        \n",
    "    def extract_BBoxes(self, root, bbox_df, file_name):\n",
    "        objects = root.findall('object')\n",
    "    \n",
    "        for obj in objects:\n",
    "            name = obj.find('name').text\n",
    "            pose = obj.find('pose').text\n",
    "            truncated = obj.find('truncated').text\n",
    "            difficult = obj.find('difficult').text\n",
    "        \n",
    "            bndbox = obj.find('bndbox')\n",
    "            xmin = int(bndbox[0].text)\n",
    "            ymin = int(bndbox[1].text)\n",
    "            xmax = int(bndbox[2].text)\n",
    "            ymax = int(bndbox[3].text)\n",
    "        \n",
    "            bbox_df = bbox_df.append({\"Name\": name, \n",
    "                                      \"Pose\": pose, \n",
    "                                      \"Truncated\": truncated, \n",
    "                                      \"Difficult\": difficult, \n",
    "                                      \"Xmin\": xmin, \n",
    "                                      \"Ymin\": ymin, \n",
    "                                      \"Xmax\": xmax, \n",
    "                                      \"Ymax\": ymax, \n",
    "                                      \"File\": file_name, \n",
    "                                      \"Dataset\": self.dataset_name}, \n",
    "                                     ignore_index=True)\n",
    "        return bbox_df\n",
    "    \n",
    "    def create_label_ID(self, label_path):\n",
    "        label_df = pd.DataFrame([], columns=[\"Label_ID\", \"Name\", \"Dataset\"])\n",
    "\n",
    "        with open(label_path, \"r\") as f:\n",
    "            lines = f.read().splitlines()\n",
    "            for idx, line in enumerate(lines):\n",
    "                label_df = label_df.append({\"Label_ID\": idx, \"Name\": line, \"Dataset\": self.dataset_name}, ignore_index=True)\n",
    "\n",
    "            self.upload_dataset2sql(label_df, \"Image_Label\")\n",
    "        \n",
    "        label_dict = label_df.set_index('Name').to_dict()\n",
    "        return label_dict[\"Label_ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "======== Connect to the remote NAS server ========\n",
      "=====================================================\n",
      "Time : 2020-12-23_23_01\n",
      "\n",
      "=====================================================\n",
      "======== Connect to the remote filestation ========\n",
      "=====================================================\n",
      "Time : 2020-12-23_23_01\n",
      "\n",
      "You are now logged in!\n",
      "connct to NAS...\n",
      "CPU Load:        6 %\n",
      "Memory Use:      46 %\n",
      "Net Up:          3798\n",
      "Net Down:        4921\n",
      "--\n",
      "=== Information ===\n",
      "Model:           DS720+\n",
      "RAM:             6144 MB\n",
      "Temperature:     35 °C\n",
      "--\n",
      "=====================================================\n",
      "======== Connect to the remote postgre SQL server ========\n",
      "=====================================================\n",
      "Time : 2020-12-23_23_01\n",
      "\n",
      "dir info\n",
      "name:  #recycle\n",
      "path:  /dataset/#recycle\n",
      "---\n",
      "dir info\n",
      "name:  VOC2007\n",
      "path:  /dataset/VOC2007\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "prefix = dataset_path.split('/')[-2]\n",
    "\n",
    "voc = VOC_Dataset(dataset_path, prefix,\n",
    "                  user=user_name, password=password, database=db_name, host_address=host_ip, port=port)\n",
    "\n",
    "voc.postgreSQL_connect()\n",
    "label_dict = voc.create_label_ID('./label/VOC2007.txt')\n",
    "voc.extract_label_info()\n",
    "voc.extract_dataset_info(nas_path='/dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_Download(SQL_Config):\n",
    "    \"\"\"\n",
    "    Download the dataset from SQL\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset_name, user=None, password=None, database=None, host_address=None, db_url=None, port=32769):\n",
    "        super().__init__(user, password, database, host_address, db_url, port)\n",
    "        self.filestation = Filestation_Config(user, password, host_address)\n",
    "        \n",
    "        self.dataset_name = dataset_name\n",
    "        self.postgreSQL_connect()\n",
    "\n",
    "    def download_label(self, sql_query=None):\n",
    "        if sql_query is None:\n",
    "            sql_query = 'SELECT * FROM \"Image_Label\" WHERE \"Dataset\"=\\'' + self.dataset_name + '\\';'\n",
    "            \n",
    "        file_name = self.dataset_name + '_label_data'\n",
    "        label_df = self.download_sql_table(sql_query, file_name)\n",
    "        return label_df\n",
    "\n",
    "    def download_BBoxes(self, sql_query=None):\n",
    "        if sql_query is None:\n",
    "            sql_query = 'SELECT * FROM \"Image_Annot\" WHERE \"Dataset\"=\\'' + self.dataset_name + '\\';'\n",
    "            \n",
    "        file_name = self.dataset_name + '_bboxes_data'\n",
    "        bboxes_df = self.download_sql_table(sql_query, file_name)\n",
    "        return bboxes_df\n",
    "        \n",
    "    def download_imageInfo(self, sql_query=None):  \n",
    "        if sql_query is None:\n",
    "            sql_query = 'SELECT * FROM \"Image_Info\" WHERE \"Dataset\"=\\'' + self.dataset_name + '\\';'\n",
    "            \n",
    "        file_name = self.dataset_name + '_image_info'\n",
    "        image_df = self.download_sql_table(sql_query, file_name)\n",
    "        return image_df\n",
    "    \n",
    "    def download_image(self, dataset_df, image_df): \n",
    "        path = dataset_df.set_index('Name').loc['VOC2007', 'Prefix_Path']\n",
    "        img_files = image_df.set_index('Dataset').loc['VOC2007', 'File_Name']\n",
    "        dst_dir = saved_path + 'image/' + self.dataset_name\n",
    "        print('Start download image...')\n",
    "        \n",
    "        for file_name in tqdm(img_files, ncols=60):\n",
    "            self.filestation.download_file(path, file_name, dst_dir)\n",
    "            \n",
    "        print('All the images are downloaded')\n",
    "        \n",
    "    def download_datasetInfo(self, sql_query=None):\n",
    "        if sql_query is None:\n",
    "            sql_query = 'SELECT * FROM \"Dataset\" WHERE \"Name\"=\\'' + self.dataset_name + '\\';'\n",
    "            \n",
    "        file_name = self.dataset_name + '_dataset'\n",
    "        dataset_df = self.download_sql_table(sql_query, file_name)\n",
    "        return dataset_df\n",
    "        \n",
    "    def download_sql_table(self, sql_query, file_name):\n",
    "        if not os.path.exists(saved_path):\n",
    "            os.makedirs(saved_path)\n",
    "            \n",
    "        print('Start to query...')\n",
    "        table_df = pd.read_sql(sql_query, self.db)\n",
    "        table_df.to_csv(saved_path + file_name + '.csv', index=False, encoding='utf_8_sig')\n",
    "        print('==> The ' + file_name + '.csv is saved \\n')\n",
    "            \n",
    "        return table_df\n",
    "        \n",
    "    def start(self):\n",
    "        label_df = self.download_label()\n",
    "        bboxes_df = self.download_BBoxes()\n",
    "        image_df = self.download_imageInfo()\n",
    "        dataset_df = self.download_datasetInfo()\n",
    "        \n",
    "        self.download_image(dataset_df, image_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "======== Connect to the remote filestation ========\n",
      "=====================================================\n",
      "Time : 2020-12-23_23_10\n",
      "\n",
      "You are now logged in!\n",
      "=====================================================\n",
      "======== Connect to the remote postgre SQL server ========\n",
      "=====================================================\n",
      "Time : 2020-12-23_23_10\n",
      "\n",
      "Start to query...\n",
      "==> The VOC2007_label_data.csv is saved \n",
      "\n",
      "Start to query...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                              | 0/5011 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> The VOC2007_bboxes_data.csv is saved \n",
      "\n",
      "Start to query...\n",
      "==> The VOC2007_image_info.csv is saved \n",
      "\n",
      "Start to query...\n",
      "==> The VOC2007_dataset.csv is saved \n",
      "\n",
      "Start download image...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████| 5011/5011 [11:25<00:00,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the images are downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Dataset_Download('VOC2007', user=user_name, password=password, database=db_name, host_address=host_ip, port=port).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
